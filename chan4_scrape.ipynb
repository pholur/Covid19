{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Coronavirus is a hoax - Politically Incorrect - 4chan\n",
    "# https://boards.4chan.org/pol/thread/252406368/coronavirus-is-a-hoax#p252406757\n",
    "# &#039;, \n",
    "from bs4 import BeautifulSoup\n",
    "from newspaper import Article\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "headers = requests.utils.default_headers()\n",
    "headers.update({ 'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:52.0) Gecko/20100101 Firefox/52.0'})\n",
    "url = \"https://boards.4chan.org/pol//thread/252821554/new-york-state-now-has-more-coronavirus-cases\"\n",
    "req = requests.get(url, headers)\n",
    "soup = BeautifulSoup(req.content, 'html.parser')\n",
    "\n",
    "list_of_posts = []\n",
    "gg = soup.find_all(\"div\")\n",
    "for g in gg:\n",
    "    y = g.get(\"class\")\n",
    "    if y == ['post','reply']:\n",
    "        list_of_posts.append(g)\n",
    "\n",
    "chan4 = {\"date_utc\":[], \"user\":[], \"responding_to\":[], \"text\":[]}\n",
    "\n",
    "for post in list_of_posts:\n",
    "    date = None\n",
    "    try:\n",
    "        id_ = post.find(\"input\").get(\"name\")\n",
    "        message = post.find('blockquote', attrs={'class':'postMessage'})\n",
    "        result = re.search('<br/>(.*)</blockquote>', str(message))\n",
    "        result_ = result.group(1)\n",
    "        result_ = re.sub(\"<.*?>\",\"\",result_)\n",
    "        result_ = re.sub(\"&#039;\",\"\",result_)\n",
    "        result_ = re.sub(\"&gt;\",\"\",result_)\n",
    "        date_utc = post.find('span', attrs={'class':'dateTime'}).get(\"data-utc\")\n",
    "        hyper_linked_user = post.find('a', attrs={'class':'quotelink'}).get(\"href\")\n",
    "        \n",
    "        chan4[\"date_utc\"].append(date_utc)\n",
    "        chan4[\"user\"].append(id_)\n",
    "        chan4[\"responding_to\"].append(hyper_linked_user[2:])\n",
    "        chan4[\"text\"].append(result_)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "Data = pd.DataFrame.from_dict(chan4)\n",
    "# chan4_new_york_has_more_corona.csv\n",
    "# Data.to_csv(\"chan4_new_york_has_more_corona.csv\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('Data/Raw_Data/Chan4/chan4_new_york_has_more_corona.csv')  \n",
    "\n",
    "import re\n",
    "alphabets= \"([A-Za-z])\"\n",
    "prefixes = \"(Mr|St|Mrs|Ms|Dr)[.]\"\n",
    "suffixes = \"(Inc|Ltd|Jr|Sr|Co)\"\n",
    "starters = \"(Mr|Mrs|Ms|Dr|He\\s|She\\s|It\\s|They\\s|Their\\s|Our\\s|We\\s|But\\s|However\\s|That\\s|This\\s|Wherever)\"\n",
    "acronyms = \"([A-Z][.][A-Z][.](?:[A-Z][.])?)\"\n",
    "websites = \"[.](com|net|org|io|gov)\"\n",
    "digits = \"([0-9])\"\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    text = \" \" + text + \"  \"\n",
    "    text = text.replace(\"\\n\",\" \")\n",
    "    text = re.sub(prefixes,\"\\\\1<prd>\",text)\n",
    "    text = re.sub(websites,\"<prd>\\\\1\",text)\n",
    "    if \"Ph.D\" in text: text = text.replace(\"Ph.D.\",\"Ph<prd>D<prd>\")\n",
    "        \n",
    "    text = re.sub(\"\\s\" + alphabets + \"[.] \",\" \\\\1<prd> \",text)\n",
    "    text = re.sub(acronyms+\" \"+starters,\"\\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\\\\3<prd>\",text)\n",
    "    text = re.sub(alphabets + \"[.]\" + alphabets + \"[.]\",\"\\\\1<prd>\\\\2<prd>\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.] \"+starters,\" \\\\1<stop> \\\\2\",text)\n",
    "    text = re.sub(\" \"+suffixes+\"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(\" \" + alphabets + \"[.]\",\" \\\\1<prd>\",text)\n",
    "    text = re.sub(digits + \"[.]\" + digits,\"\\\\1<prd>\\\\2\",text)\n",
    "    \n",
    "    if \"”\" in text: text = text.replace(\".”\",\"”.\")\n",
    "    if \"\\\"\" in text: text = text.replace(\".\\\"\",\"\\\".\")\n",
    "    if \"!\" in text: text = text.replace(\"!\\\"\",\"\\\"!\")\n",
    "    if \"?\" in text: text = text.replace(\"?\\\"\",\"\\\"?\")\n",
    "        \n",
    "    text = text.replace(\".\",\".<stop>\")\n",
    "    text = text.replace(\"?\",\"?<stop>\")\n",
    "    text = text.replace(\"!\",\"!<stop>\")\n",
    "    text = text.replace(\"<prd>\",\".\")\n",
    "    \n",
    "    sentences = text.split(\"<stop>\")\n",
    "    sentences = sentences[:-1]\n",
    "    sentences = [s.strip() for s in sentences]\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/Extracted_Data/chan4/into_relex.txt\", \"a+\") as file_object:\n",
    "    file_object.write(\"text\\n\")\n",
    "    for _,row in data.iterrows():\n",
    "        file_object.write(str(row[\"text\"]) + \"\\n\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
