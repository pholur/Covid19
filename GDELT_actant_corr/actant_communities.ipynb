{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bit4bd693e9780a48afbf8d298023c65066",
   "display_name": "Python 3.7.3 64-bit"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASIC IMPORTS OF ALL LIBRARIES\n",
    "'''\n",
    "Glove Imports are 300-dim from GENSIM\n",
    "Pickle saves all the datasets\n",
    "'''\n",
    "import pygraphviz\n",
    "from nltk import pos_tag\n",
    "import csv\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "from graphviz import Source\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.spatial.distance import cdist \n",
    "import gensim.downloader as api\n",
    "from networkx.algorithms.community import greedy_modularity_communities\n",
    "from sklearn.preprocessing import normalize\n",
    "from datetime import datetime, timedelta\n",
    "import datetime\n",
    "\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# junk verbs that are generalizably illegal\n",
    "junk_rel = [\"be\",\"have\",\"do\",\"let\",\"\",\"make\",\"tell\",\"say\",\"describe\",\"decide\",\"want\",\"name\",\"know\",\"think\",\"try\",\"become\",\"oneday\",\"put\",\"come\",'see', 'need', 'look', 'help', 'come', 'take', 'get', 'put', 'pick', 'turn', 'go', 'stand', 'give', 'notice', 'use',\"get\",\"start\"]\n",
    "\n",
    "# hypothetical words that are generally useless / qualifiers\n",
    "junk_words = [\"would\",\"could\",\"should\",\"maybe\",\"perhaps\",\"think\",\"might\",\"assume\",\"claim\",\"this\"]\n",
    "\n",
    "# negative sentences\n",
    "junk_words.extend(['n\\'t',\"not\"])\n",
    "\n",
    "# perspective actants that are pointless\n",
    "junk = [\"you\",\"i\",\"we\",\"the\",\"it\",\"he\",\"she\",\"steinbeck\",\"people\",\"author\",\n",
    "        \"book\",\"me\",\"steinback\",\"him\",\"her\",\"their\",\"this\",\"\",\"shelley\",\"mary\",\"harper\",\"lee\",\"tolkien\",\"bjp\",\"delhi\",\"man\",\"men\",\"giannulli\",\"loughlin\",\"singh\",\"ryan\",\"way\",\"lot\",\"guy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "entity_file = \"NER_list.csv\"\n",
    "S_use = {}\n",
    "# fill this in\n",
    "\n",
    "places = []\n",
    "people = []\n",
    "orgs = []\n",
    "\n",
    "ent_file = pd.read_csv(entity_file)\n",
    "for row in ent_file.head(100).iterrows():\n",
    "     S_use[row[1]['entity']] = row[1]['entity']\n",
    "\n",
    "for row in ent_file.iterrows():\n",
    "    if row[1]['type'] == \"PERSON\":\n",
    "        people.append(row[1]['entity'])\n",
    "        # S_use[row[1]['entity']] = row[1]['entity']\n",
    "\n",
    "for row in ent_file.iterrows():\n",
    "    if row[1]['type'] == \"GPE\":\n",
    "        places.append(row[1]['entity'])\n",
    "        # S_use[row[1]['entity']] = row[1]['entity']\n",
    "\n",
    "for row in ent_file.iterrows():\n",
    "    if row[1]['type'] == \"ORG\":\n",
    "        orgs.append(row[1]['entity'])\n",
    "        # S_use[row[1]['entity']] = row[1]['entity']\n",
    "\n",
    "ads = [\"youtube\",\"twitter\",\"facebook\",\"reddit\",\"4chan\",\"8chan\",\"instagram\"]\n",
    "hardcode = [\"5g\",\"radio\",\"waves\",\"jews\",\"army\",\"nanowires\",\"alien\",\"aliens\",\"towers\",\"bleach\",\"garlic\"]\n",
    "# for a in ads:\n",
    "#     S_use[a] = a\n",
    "\n",
    "# for a in hardcode:\n",
    "#     S_use[a] = a\n",
    "    \n",
    "# S_use[\"alex\"] = \"alex jones\"\n",
    "# S_use[\"jones\"] = \"alex jones\"\n",
    "# S_use[\"virus\"] = \"covid19\"\n",
    "# S_use[\"coronavirus\"] = \"covid19\"\n",
    "# S_use[\"theory\"] = \"conspiracy theory\"\n",
    "# S_use[\"theories\"] = \"conspiracy theory\"\n",
    "# S_use[\"conspiracy\"] = \"conspiracy theory\"\n",
    "# S_use[\"trumps\"] = S_use[\"trump\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"ExtractedGDELTData/\"\n",
    "date_start = \"20200101000001\"\n",
    "date_end = \"20200410000001\"\n",
    "#date_end = \"20200102000001\"\n",
    "date = date_start\n",
    "results = \"Results0423\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_traj(file_name_re, S):\n",
    "    trajectories = []\n",
    "    same_post = 0\n",
    "    traj = [\"START\"]\n",
    "\n",
    "    with open(file_name_re) as csvfile:\n",
    "        readCSV = csv.reader(csvfile, delimiter=',')\n",
    "\n",
    "        for row in readCSV:\n",
    "            FLAG = 0\n",
    "            sentence_num = row[1]\n",
    "            sub_r = \"\"\n",
    "            obj_r = \"\"\n",
    "            sub_verb = \"\"\n",
    "\n",
    "            sub = \"\"\n",
    "            obj = \"\"\n",
    "            rel = \"\"\n",
    "            try:\n",
    "                sub = re.search(r\"\\{(\\w+)\\}\", row[3]).group(1).lower()\n",
    "                rel = wnl.lemmatize(re.search(r\"\\{(\\w+)\\}\", row[4]).group(1).lower(), pos='v')\n",
    "                obj = re.search(r\"\\{(\\w+)\\}\", row[5]).group(1).lower()\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            words = row[2].split()\n",
    "            rel_words = []\n",
    "\n",
    "\n",
    "            if rel == None or obj == None or sub == None:\n",
    "                continue\n",
    "            \n",
    "            if same_post == row[0]:\n",
    "                pass\n",
    "            else:\n",
    "                same_post = row[0]\n",
    "                traj.append(\"TERMINATE\")\n",
    "                trajectories.append(traj)\n",
    "                traj = [\"START\"]\n",
    "\n",
    "            try:\n",
    "                sub_r = S[sub]\n",
    "            except:\n",
    "                sub_r = sub\n",
    "                FLAG += 1\n",
    "            \n",
    "            try:\n",
    "                obj_r = S[obj]\n",
    "            except:\n",
    "                obj_r = obj\n",
    "                FLAG += 1\n",
    "\n",
    "            sub_verb = \"\"\n",
    "            sub_verb = rel\n",
    "\n",
    "            if sub_r == obj_r or sub_r in junk or obj_r in junk or sub_verb in junk_rel \\\n",
    "                                    or FLAG > 0 or sub_r.isdigit() or obj_r.isdigit():\n",
    "                continue\n",
    "\n",
    "            traj.append(sub_verb)\n",
    "            traj.append(sub_r + \"_\" + obj_r + \"_\" + sentence_num)\n",
    "\n",
    "    # if we missed out on last post\n",
    "    if traj != \"START\":\n",
    "        traj.append(\"TERMINATE\")\n",
    "        trajectories.append(traj)\n",
    "    return trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mat(trajectories):\n",
    "    rev_dict = {}\n",
    "    precedence_matrix = np.zeros((50000,50000))\n",
    "    dictionary_of_labels = {\"START\":0, \"TERMINATE\":1}\n",
    "    counter_of_labels = defaultdict(int)\n",
    "    max_rows = 1\n",
    "    max_cols = 1\n",
    "    counter = 2\n",
    "\n",
    "    for trajectory in trajectories:\n",
    "\n",
    "        triplets = [\"START\"]\n",
    "        index = 1\n",
    "\n",
    "        while index < len(trajectory)-2:\n",
    "            triplets.append(trajectory[index] + '_' + trajectory[index + 1])\n",
    "            index += 2\n",
    "\n",
    "        triplets.append(\"TERMINATE\")\n",
    "\n",
    "        for key,_ in enumerate(triplets[1:-1]):\n",
    "            removed_triplets = triplets[key+1].split(\"_\")\n",
    "            if len(removed_triplets) > 1:\n",
    "                subject_ = removed_triplets[1]\n",
    "                object_ = removed_triplets[2]\n",
    "                if subject_ not in dictionary_of_labels:\n",
    "                    dictionary_of_labels[subject_] = counter\n",
    "                    counter += 1\n",
    "                if object_ not in dictionary_of_labels:\n",
    "                    dictionary_of_labels[object_] = counter\n",
    "                    counter += 1\n",
    "        \n",
    "        triplet_temp = []\n",
    "\n",
    "        # find uniques\n",
    "        for trip in triplets:\n",
    "            try:\n",
    "                removed_triplet = trip.rsplit(\"_\",1)[0]\n",
    "            except:\n",
    "                removed_triplet = trip\n",
    "\n",
    "            if removed_triplet not in [t.rsplit(\"_\",1)[0] for t in triplet_temp]:\n",
    "                triplet_temp.append(trip)\n",
    "\n",
    "        triplets = triplet_temp\n",
    "\n",
    "        # for trip in triplets:\n",
    "        #     counter_of_labels[trip] += 1\n",
    "\n",
    "        alpha = 1.0\n",
    "\n",
    "        for key in range(1,len(triplets)):\n",
    "            removed_triplets = triplets[key].split(\"_\")\n",
    "            try:\n",
    "                subject_ = removed_triplets[1]\n",
    "                object_ = removed_triplets[2]\n",
    "                precedence_matrix[dictionary_of_labels[subject_]]\\\n",
    "                                            [dictionary_of_labels[object_]] += 1.0\n",
    "                precedence_matrix[dictionary_of_labels[object_]]\\\n",
    "                                            [dictionary_of_labels[subject_]] += 1.0\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "\n",
    "    precedence_matrix = precedence_matrix[:counter,:counter]\n",
    "    for key in dictionary_of_labels:\n",
    "        rev_dict[dictionary_of_labels[key]] = key\n",
    "\n",
    "    return precedence_matrix, dictionary_of_labels, rev_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_partitions(G, rev_dict, date_):\n",
    "    list_of_comms = greedy_modularity_communities(G)\n",
    "    total_l = []\n",
    "    with open(results + \"/communities.txt\",\"a+\") as f:\n",
    "        for l in list_of_comms:\n",
    "            temp_list = []\n",
    "            for i in l:\n",
    "                if i not in [0,1]:\n",
    "                    temp_list.append(rev_dict[i])\n",
    "\n",
    "            if temp_list != []:\n",
    "                str_l = ', '.join(temp_list)\n",
    "                total_l.append(\"{\" + str_l + \"}\")\n",
    "        final_str = \", \".join(total_l) + \"\\n\"\n",
    "        f.write(date_ + \" -> \" + final_str)\n",
    "\n",
    "\n",
    "def save_simple_paths(G, dic):\n",
    "    w1 = \"coronavirus\"\n",
    "    w2 = \"conspiracy theory\"\n",
    "    print(dic)\n",
    "    with open(results + \"/simple_path.txt\",\"a+\") as f:\n",
    "        if w1 in dic and w2 in dic:\n",
    "            f.write(str(len(list(nx.all_simple_paths(G, source=dic[w1], target=dic[w2], cutoff = 2)))))\n",
    "            f.write(\"\\n\")\n",
    "        else:\n",
    "            f.write(str(0))\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fig(trajectories,label):    \n",
    "    sub_t = trajectories\n",
    "    mat, dic, rev_dict = find_mat(sub_t)\n",
    "    try:\n",
    "        mat = normalize(mat, 'l1')\n",
    "        for i in range(0, mat.shape[0]):\n",
    "            for j in range(0, mat.shape[1]):\n",
    "                if mat[i][j] > mat[j][i]:\n",
    "                    mat[j][i] = 0\n",
    "\n",
    "                elif mat[i][j] < mat[j][i]:\n",
    "                    mat[i][j] = 0\n",
    "\n",
    "                elif mat[i][j] == mat[j][i] and i != j and mat[j][i] != 0:\n",
    "                    mat[j][i] = 0\n",
    "\n",
    "        G = nx.from_numpy_matrix(mat, create_using=nx.Graph)\n",
    "        save_partitions(G, rev_dict, label[4:8])\n",
    "    except:\n",
    "        G = nx.from_numpy_matrix(mat, create_using=nx.Graph)\n",
    "\n",
    "    DISP_THRESH = 2\n",
    "\n",
    "    bb = {}\n",
    "    for index, val in np.ndenumerate(mat):\n",
    "        if val > 1:\n",
    "            bb[index] = {\"color\":\"red\", \"penwidth\":2}\n",
    "        else:\n",
    "            bb[index] = {\"color\":\"blue\", \"penwidth\":0.5}\n",
    "    nx.set_edge_attributes(G, bb)\n",
    "\n",
    "    bb1 = {}\n",
    "    for j in range(mat.shape[0]):\n",
    "        if rev_dict[j] in places:\n",
    "            bb1[j] = {\"color\":\"green\", \"penwidth\":4}\n",
    "        if rev_dict[j] in people:\n",
    "            bb1[j] = {\"color\":\"yellow\", \"penwidth\":4}\n",
    "        if rev_dict[j] in orgs:\n",
    "            bb1[j] = {\"color\":\"black\", \"penwidth\":4}\n",
    "        if rev_dict[j] in ads:\n",
    "            bb1[j] = {\"color\":\"red\", \"penwidth\":4}\n",
    "        if rev_dict[j] in hardcode:\n",
    "            bb1[j] = {\"color\":\"pink\", \"penwidth\":4}\n",
    "        if rev_dict[j] == \"coronavirus\":\n",
    "            bb1[j] = {\"color\":\"orange\", \"penwidth\":6}\n",
    "        if rev_dict[j] == \"conspiracy theory\":\n",
    "            bb1[j] = {\"color\":\"orange\", \"penwidth\":6}\n",
    "\n",
    "    nx.set_node_attributes(G, bb1)\n",
    "    save_simple_paths(G, dic)\n",
    "    H = nx.relabel_nodes(G, rev_dict)\n",
    "\n",
    "    H.remove_nodes_from(list(nx.isolates(H)))\n",
    "    A = nx.nx_agraph.to_agraph(H)\n",
    "\n",
    "    A.layout('fdp')\n",
    "    A.draw(results + \"/Actant_TimeSeries/step\" + str(label) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def to_date(DATE):\n",
    "    return datetime.strptime(DATE, '%Y%m%d%H%M%S')\n",
    "\n",
    "def from_date(DATE):\n",
    "    return DATE.strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "def create_range(DATE):\n",
    "    list_dates = []\n",
    "    for i in range(5):\n",
    "        list_dates.append(DATE + timedelta(days = i))\n",
    "    return list_dates\n",
    "\n",
    "def create_dict(string_of_words):\n",
    "    S = {}\n",
    "    words = string_of_words.split(\", \")\n",
    "    for word in words:\n",
    "        # REMOVE FOR VERSION 2\n",
    "        if word in [\"mr\",\"gandhi\",\"thakur\",\"pulwama\"]:\n",
    "            continue\n",
    "\n",
    "        S[word] = word\n",
    "        if word in [\"theories\",\"theory\",\"conspiracy\"]:\n",
    "            S[word] = \"conspiracy theory\"\n",
    "        if word == \"alex\" or word == \"jones\":\n",
    "            S[word] = \"alex jones\"\n",
    "        if word == \"trump\" or word == \"trumps\":\n",
    "            S[word] = \"donald trump\"\n",
    "        if word == \"virus\" or word == \"coronavirus\" or word == \"covid19\":\n",
    "            S[word] = \"coronavirus\"\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": " 14, 'country': 15, 'everyone': 16, 'corona': 17, 'anyone': 18, 'usa': 19, 'spread': 20, 'africa': 21, 'system': 22, 'gates': 23, 'research': 24, 'cdc': 25, 'covid19': 26, 'doctors': 27, 'doctor': 28, 'wuhan': 29, 'israel': 30, 'cases': 31, 'deaths': 32, 'iran': 33, 'symptoms': 34, 'evidence': 35, 'years': 36, 'syria': 37, 'hospitals': 38, 'two': 39, 'hospital': 40, 'countries': 41, 'outbreak': 42, 'government': 43, 'cia': 44, 'idea': 45, 'nothing': 46, 'post': 47, 'questions': 48, 'march': 49, 'jews': 50, 'west': 51, 'cells': 52, 'year': 53, 'sars': 54, 'american': 55}\n{'START': 0, 'TERMINATE': 1, 'us': 0, 'conspiracy theory': 1, 'trump': 2, 'coronavirus': 3, 'doctors': 4, 'covid19': 5, 'lab': 6, 'doctor': 7, 'media': 8, 'pandemic': 9, 'disease': 10, 'wuhan': 11, 'china': 12, 'americans': 13, 'israel': 14, 'cases': 15, 'deaths': 16, 'world': 17, 'iran': 18, 'symptoms': 19, 'evidence': 20, 'sunday': 21, 'system': 22, 'years': 23, 'syria': 24, 'country': 25, 'hospitals': 26, 'two': 27, 'hospital': 28, 'spread': 29, 'government': 30, 'cia': 31, 'everyone': 32, 'idea': 33, 'nothing': 34, 'anyone': 35, 'gates': 36, 'post': 37, 'questions': 38, 'march': 39, 'jews': 40, 'west': 41, 'cells': 42, 'year': 43, 'research': 44, 'countries': 45, 'africa': 46, 'american': 47, 'information': 48, 'viruses': 49, 'flu': 50, 'point': 51, 'thing': 52, 'life': 53}\n{'START': 0, 'TERMINATE': 1, 'cases': 0, 'deaths': 1, 'pandemic': 2, 'world': 3, 'iran': 4, 'coronavirus': 5, 'us': 6, 'conspiracy theory': 7, 'symptoms': 8, 'evidence': 9, 'americans': 10, 'sunday': 11, 'system': 12, 'years': 13, 'syria': 14, 'country': 15, 'hospitals': 16, 'two': 17, 'hospital': 18, 'spread': 19, 'government': 20, 'cia': 21, 'covid19': 22, 'disease': 23, 'israel': 24, 'everyone': 25, 'idea': 26, 'lab': 27, 'state': 28, 'media': 29, 'nothing': 30, 'anyone': 31, 'gates': 32, 'post': 33, 'questions': 34, 'march': 35, 'jews': 36, 'west': 37, 'wuhan': 38, 'cells': 39, 'trump': 40, 'research': 41, 'china': 42, 'countries': 43, 'africa': 44, 'american': 45, 'information': 46, 'viruses': 47, 'flu': 48, 'point': 49, 'thing': 50, 'life': 51, 'time': 52, 'vaccine': 53, 'something': 54, 'cdc': 55, 'news': 56, 'america': 57}\n{'START': 0, 'TERMINATE': 1, 'everyone': 0, 'conspiracy theory': 1, 'idea': 2, 'coronavirus': 3, 'disease': 4, 'lab': 5, 'state': 6, 'media': 7, 'pandemic': 8, 'nothing': 9, 'evidence': 10, 'china': 11, 'cent': 12, 'anyone': 13, 'police': 14, 'us': 15, 'gates': 16, 'cases': 17, 'deaths': 18, 'post': 19, 'questions': 20, 'iran': 21, 'government': 22, 'march': 23, 'jews': 24, 'west': 25, 'covid19': 26, 'wuhan': 27, 'cells': 28, 'trump': 29, 'research': 30, 'countries': 31, 'elba': 32, 'court': 33, 'africa': 34, 'american': 35, 'information': 36, 'world': 37, 'viruses': 38, 'flu': 39, 'point': 40, 'thing': 41, 'someone': 42, 'life': 43, 'time': 44, 'israel': 45, 'vaccine': 46, 'something': 47, 'cdc': 48, 'hospitals': 49, 'country': 50, 'news': 51, 'system': 52, 'america': 53, 'times': 54, 'work': 55, 'uh': 56}\n{'START': 0, 'TERMINATE': 1, 'post': 0, 'media': 1, 'conspiracy theory': 2, 'everyone': 3, 'us': 4, 'iran': 5, 'covid19': 6, 'disease': 7, 'research': 8, 'march': 9, 'coronavirus': 10, 'china': 11, 'countries': 12, 'lab': 13, 'cases': 14, 'pandemic': 15, 'elba': 16, 'idea': 17, 'government': 18, 'africa': 19, 'wuhan': 20, 'trump': 21, 'american': 22, 'information': 23, 'cells': 24, 'world': 25, 'viruses': 26, 'flu': 27, 'state': 28, 'nothing': 29, 'evidence': 30, 'point': 31, 'thing': 32, 'someone': 33, 'life': 34, 'jews': 35, 'time': 36, 'israel': 37, 'vaccine': 38, 'something': 39, 'doctors': 40, 'public': 41, 'deaths': 42, 'cdc': 43, 'hospitals': 44, 'country': 45, 'questions': 46, 'news': 47, 'system': 48, 'america': 49, 'times': 50, 'gates': 51, 'work': 52, 'uh': 53, 'health': 54, 'americans': 55, 'chinese': 56, 'doctor': 57, 'patients': 58}\n{'START': 0, 'TERMINATE': 1, 'conspiracy theory': 0, 'idea': 1, 'pandemic': 2, 'world': 3, 'viruses': 4, 'flu': 5, 'elba': 6, 'coronavirus': 7, 'trump': 8, 'state': 9, 'media': 10, 'nothing': 11, 'evidence': 12, 'covid19': 13, 'point': 14, 'countries': 15, 'thing': 16, 'someone': 17, 'life': 18, 'jews': 19, 'time': 20, 'israel': 21, 'china': 22, 'vaccine': 23, 'something': 24, 'doctors': 25, 'public': 26, 'lab': 27, 'wuhan': 28, 'deaths': 29, 'cdc': 30, 'us': 31, 'cases': 32, 'hospitals': 33, 'country': 34, 'questions': 35, 'government': 36, 'news': 37, 'system': 38, 'america': 39, 'times': 40, 'gates': 41, 'work': 42, 'uh': 43, 'disease': 44, 'health': 45, 'information': 46, 'americans': 47, 'chinese': 48, 'doctor': 49, 'patients': 50, 'iran': 51, 'fauci': 52, 'post': 53, 'cells': 54, 'fact': 55, 'video': 56, 'youtube': 57}\n{'START': 0, 'TERMINATE': 1, 'jews': 0, 'time': 1, 'media': 2, 'israel': 3, 'world': 4, 'countries': 5, 'covid19': 6, 'china': 7, 'vaccine': 8, 'coronavirus': 9, 'conspiracy theory': 10, 'something': 11, 'doctors': 12, 'public': 13, 'lab': 14, 'wuhan': 15, 'deaths': 16, 'cdc': 17, 'us': 18, 'cases': 19, 'pandemic': 20, 'hospitals': 21, 'viruses': 22, 'flu': 23, 'donald trump': 24, 'country': 25, 'evidence': 26, 'questions': 27, 'government': 28, 'news': 29, 'system': 30, 'america': 31, 'times': 32, 'gates': 33, 'work': 34, 'uh': 35, 'disease': 36, 'health': 37, 'information': 38, 'americans': 39, 'chinese': 40, 'doctor': 41, 'patients': 42, 'iran': 43, 'someone': 44, 'thing': 45, 'point': 46, 'fauci': 47, 'post': 48, 'cells': 49, 'fact': 50, 'police': 51, 'video': 52, 'youtube': 53, 'hospital': 54, 'op': 55, 'nyc': 56, 'everyone': 57, 'truth': 58}\n{'START': 0, 'TERMINATE': 1, 'conspiracy theory': 0, 'times': 1, 'coronavirus': 2, 'covid19': 3, 'gates': 4, 'flu': 5, 'work': 6, 'pandemic': 7, 'world': 8, 'viruses': 9, 'donald trump': 10, 'country': 11, 'china': 12, 'israel': 13, 'vaccine': 14, 'something': 15, 'doctors': 16, 'public': 17, 'us': 18, 'media': 19, 'uh': 20, 'time': 21, 'deaths': 22, 'disease': 23, 'lab': 24, 'jews': 25, 'health': 26, 'government': 27, 'information': 28, 'americans': 29, 'chinese': 30, 'doctor': 31, 'patients': 32, 'news': 33, 'iran': 34, 'someone': 35, 'thing': 36, 'point': 37, 'fauci': 38, 'post': 39, 'wuhan': 40, 'cells': 41, 'fact': 42, 'police': 43, 'video': 44, 'youtube': 45, 'hospitals': 46, 'hospital': 47, 'cases': 48, 'op': 49, 'nyc': 50, 'everyone': 51, 'countries': 52, 'system': 53, 'truth': 54, 'anyone': 55, 'usa': 56, 'america': 57}\n{'START': 0, 'TERMINATE': 1, 'coronavirus': 0, 'health': 1, 'government': 2, 'public': 3, 'information': 4, 'world': 5, 'conspiracy theory': 6, 'china': 7, 'us': 8, 'media': 9, 'disease': 10, 'lab': 11, 'americans': 12, 'chinese': 13, 'pandemic': 14, 'doctor': 15, 'patients': 16, 'news': 17, 'country': 18, 'covid19': 19, 'iran': 20, 'someone': 21, 'thing': 22, 'donald trump': 23, 'point': 24, 'time': 25, 'fauci': 26, 'times': 27, 'post': 28, 'wuhan': 29, 'cells': 30, 'fact': 31, 'police': 32, 'video': 33, 'youtube': 34, 'hospitals': 35, 'jews': 36, 'hospital': 37, 'cases': 38, 'op': 39, 'nyc': 40, 'everyone': 41, 'doctors': 42, 'vaccine': 43, 'countries': 44, 'system': 45, 'truth': 46, 'anyone': 47, 'usa': 48, 'israel': 49, 'america': 50, 'something': 51, 'questions': 52, 'idea': 53, 'deaths': 54, 'west': 55, 'flu': 56, 'research': 57, 'anything': 58, 'work': 59}\n{'START': 0, 'TERMINATE': 1, 'government': 0, 'information': 1, 'world': 2, 'point': 3, 'us': 4, 'conspiracy theory': 5, 'china': 6, 'coronavirus': 7, 'media': 8, 'time': 9, 'fauci': 10, 'president': 11, 'times': 12, 'post': 13, 'donald trump': 14, 'pandemic': 15, 'disease': 16, 'covid19': 17, 'wuhan': 18, 'cells': 19, 'fact': 20, 'police': 21, 'video': 22, 'youtube': 23, 'news': 24, 'hospitals': 25, 'patients': 26, 'jews': 27, 'americans': 28, 'hospital': 29, 'cases': 30, 'country': 31, 'op': 32, 'nyc': 33, 'everyone': 34, 'doctors': 35, 'vaccine': 36, 'iran': 37, 'countries': 38, 'system': 39, 'truth': 40, 'anyone': 41, 'thing': 42, 'chinese': 43, 'usa': 44, 'israel': 45, 'america': 46, 'something': 47, 'lab': 48, 'questions': 49, 'idea': 50, 'deaths': 51, 'west': 52, 'flu': 53, 'tian': 54, 'research': 55, 'anything': 56, 'work': 57, 'person': 58, 'viruses': 59, 'right': 60, 'evidence': 61, 'sense': 62, 'things': 63, 'state': 64, 'facebook': 65, 'cdc': 66, 'someone': 67, 'symptoms': 68, 'africa': 69}\n{'START': 0, 'TERMINATE': 1, 'us': 0, 'news': 1, 'pandemic': 2, 'hospitals': 3, 'video': 4, 'conspiracy theory': 5, 'coronavirus': 6, 'disease': 7, 'media': 8, 'patients': 9, 'government': 10, 'china': 11, 'covid19': 12, 'jews': 13, 'americans': 14, 'fauci': 15, 'times': 16, 'post': 17, 'donald trump': 18, 'hospital': 19, 'cases': 20, 'country': 21, 'op': 22, 'nyc': 23, 'everyone': 24, 'doctors': 25, 'vaccine': 26, 'iran': 27, 'countries': 28, 'system': 29, 'truth': 30, 'time': 31, 'point': 32, 'police': 33, 'anyone': 34, 'information': 35, 'thing': 36, 'chinese': 37, 'usa': 38, 'israel': 39, 'world': 40, 'america': 41, 'something': 42, 'lab': 43, 'questions': 44, 'wuhan': 45, 'idea': 46, 'deaths': 47, 'west': 48, 'flu': 49, 'tian': 50, 'research': 51, 'anything': 52, 'work': 53, 'person': 54, 'viruses': 55, 'right': 56, 'evidence': 57, 'sense': 58, 'things': 59, '5g': 60, 'facebook': 61, 'fact': 62, 'cdc': 63, 'someone': 64, 'symptoms': 65, 'africa': 66, 'uk': 67, 'cells': 68, 'everything': 69, 'health': 70}\n{'START': 0, 'TERMINATE': 1, 'conspiracy theory': 0, 'outbreak': 1, 'time': 2, 'jews': 3, 'point': 4, 'police': 5, 'anyone': 6, 'information': 7, 'thing': 8, 'coronavirus': 9, 'chinese': 10, 'americans': 11, 'spread': 12, 'china': 13, 'usa': 14, 'israel': 15, 'world': 16, 'cases': 17, 'country': 18, 'pandemic': 19, 'iran': 20, 'america': 21, 'media': 22, 'donald trump': 23, 'us': 24, 'something': 25, 'times': 26, 'video': 27, 'lab': 28, 'questions': 29, 'wuhan': 30, 'idea': 31, 'government': 32, 'system': 33, 'news': 34, 'doctors': 35, 'deaths': 36, 'west': 37, 'vaccine': 38, 'flu': 39, 'disease': 40, 'covid19': 41, 'patients': 42, 'hospital': 43, 'tian': 44, 'research': 45, 'truth': 46, 'anything': 47, 'post': 48, 'work': 49, 'fauci': 50, 'person': 51, 'viruses': 52, 'evidence': 53, 'sense': 54, 'things': 55, 'hospitals': 56, '5g': 57, 'facebook': 58, 'fact': 59, 'countries': 60, 'cdc': 61, 'someone': 62, 'symptoms': 63, 'africa': 64, 'masts': 65, 'uk': 66, 'cells': 67, 'everything': 68, 'health': 69, 'gates': 70}\n{'START': 0, 'TERMINATE': 1, 'conspiracy theory': 0, 'jews': 1, 'times': 2, 'coronavirus': 3, 'video': 4, 'lab': 5, 'questions': 6, 'donald trump': 7, 'media': 8, 'time': 9, 'wuhan': 10, 'pandemic': 11, 'china': 12, 'police': 13, 'anyone': 14, 'information': 15, 'idea': 16, 'government': 17, 'system': 18, 'news': 19, 'doctors': 20, 'deaths': 21, 'west': 22, 'us': 23, 'iran': 24, 'vaccine': 25, 'flu': 26, 'world': 27, 'spread': 28, 'disease': 29, 'covid19': 30, 'patients': 31, 'hospital': 32, 'tian': 33, 'outbreak': 34, 'research': 35, 'truth': 36, 'anything': 37, 'post': 38, 'work': 39, 'country': 40, 'fauci': 41, 'person': 42, 'viruses': 43, 'evidence': 44, 'thing': 45, 'sense': 46, 'things': 47, 'hospitals': 48, '5g': 49, 'facebook': 50, 'fact': 51, 'countries': 52, 'cdc': 53, 'someone': 54, 'symptoms': 55, 'africa': 56, 'masts': 57, 'uk': 58, 'something': 59, 'cells': 60, 'everything': 61, 'health': 62, 'americans': 63, 'mast': 64, 'gates': 65, 'cases': 66}\n{'START': 0, 'TERMINATE': 1, 'trump': 0, 'country': 1, 'fauci': 2, 'conspiracy theory': 3, 'person': 4, 'coronavirus': 5, 'work': 6, 'viruses': 7, 'flu': 8, 'world': 9, 'evidence': 10, 'covid19': 11, 'thing': 12, 'sense': 13, 'things': 14, 'disease': 15, 'pandemic': 16, 'west': 17, 'government': 18, 'system': 19, 'news': 20, 'china': 21, 'doctors': 22, 'deaths': 23, 'us': 24, 'hospitals': 25, 'patients': 26, 'lab': 27, '5g': 28, 'wuhan': 29, 'post': 30, 'facebook': 31, 'fact': 32, 'countries': 33, 'research': 34, 'truth': 35, 'someone': 36, 'symptoms': 37, 'time': 38, 'africa': 39, 'spread': 40, 'media': 41, 'anyone': 42, 'masts': 43, 'information': 44, 'uk': 45, 'something': 46, 'times': 47, 'cells': 48, 'hospital': 49, 'everything': 50, 'towers': 51, 'nothing': 52, 'networks': 53, 'harrelson': 54, 'video': 55, 'health': 56, 'americans': 57, 'iran': 58, 'woody': 59, 'point': 60, 'cases': 61, 'gates': 62, 'youtube': 63, 'chinese': 64, 'covid': 65}\n{'START': 0, 'TERMINATE': 1, 'government': 0, 'conspiracy theory': 1, 'coronavirus': 2, 'us': 3, 'lab': 4, 'china': 5, 'spread': 6, '5g': 7, 'pandemic': 8, 'media': 9, 'covid19': 10, 'anyone': 11, 'masts': 12, 'country': 13, 'information': 14, 'uk': 15, 'countries': 16, 'something': 17, 'world': 18, 'system': 19, 'wuhan': 20, 'post': 21, 'times': 22, 'evidence': 23, 'facebook': 24, 'hospitals': 25, 'patients': 26, 'cells': 27, 'hospital': 28, 'person': 29, 'everything': 30, 'towers': 31, 'nothing': 32, 'disease': 33, 'networks': 34, 'harrelson': 35, 'video': 36, 'health': 37, 'americans': 38, 'research': 39, 'iran': 40, 'symptoms': 41, 'work': 42, 'someone': 43, 'africa': 44, 'woody': 45, 'news': 46, 'point': 47, 'cases': 48, 'time': 49, 'viruses': 50, 'fact': 51, 'fauci': 52, 'gates': 53, 'doctors': 54, 'youtube': 55, 'chinese': 56, 'covid': 57, 'sense': 58, 'thing': 59}\n{'START': 0, 'TERMINATE': 1, 'conspiracy theory': 0, 'facebook': 1, 'video': 2, 'times': 3, 'us': 4, 'research': 5, 'masts': 6, 'uk': 7, 'towers': 8, 'pandemic': 9, 'coronavirus': 10, 'iran': 11, 'virus': 12, 'evidence': 13, '5g': 14, 'networks': 15, 'spread': 16, 'symptoms': 17, 'work': 18, 'media': 19, 'someone': 20, 'africa': 21, 'disease': 22, 'government': 23, 'woody': 24, 'harrelson': 25, 'news': 26, 'point': 27, 'cases': 28, 'time': 29, 'system': 30, 'person': 31, 'viruses': 32, 'cells': 33, 'fact': 34, 'china': 35, 'information': 36, 'world': 37, 'fauci': 38, 'gates': 39, 'covid19': 40, 'doctors': 41, 'patients': 42, 'birmingham': 43, 'americans': 44, 'anyone': 45, 'post': 46, 'wuhan': 47, 'youtube': 48, 'chinese': 49, 'countries': 50, 'covid': 51, 'sense': 52, 'something': 53, 'thing': 54, 'robinson': 55, 'immigration': 56, 'health': 57, 'charge': 58, 'vaccine': 59, 'american': 60, 'everyone': 61}\n{'START': 0, 'TERMINATE': 1, 'conspiracy theory': 0, 'covid19': 1, '5g': 2, 'towers': 3, 'post': 4, 'coronavirus': 5, 'uk': 6, 'wuhan': 7, 'fact': 8, 'anyone': 9, 'information': 10, 'system': 11, 'networks': 12, 'pandemic': 13, 'symptoms': 14, 'work': 15, 'cases': 16, 'time': 17, 'person': 18, 'iran': 19, 'viruses': 20, 'cells': 21, 'video': 22, 'africa': 23, 'disease': 24, 'us': 25, 'facebook': 26, 'harrelson': 27, 'media': 28, 'spread': 29, 'government': 30, 'news': 31, 'world': 32, 'times': 33, 'evidence': 34, 'youtube': 35, 'woody': 36, 'chinese': 37, 'countries': 38, 'americans': 39, 'someone': 40, 'covid': 41, 'sense': 42, 'something': 43, 'thing': 44, 'china': 45, 'robinson': 46, 'immigration': 47, 'health': 48, 'charge': 49, 'vaccine': 50, 'american': 51, 'gates': 52, 'everyone': 53, 'doctor': 54, 'deaths': 55, 'patients': 56, 'everything': 57, 'fauci': 58, 'idea': 59, 'things': 60, 'point': 61, 'numbers': 62}\n{'START': 0, 'TERMINATE': 1, 'conspiracy theory': 0, 'news': 1, '5g': 2, 'spread': 3, 'time': 4, 'symptoms': 5, 'coronavirus': 6, 'post': 7, 'times': 8, 'video': 9, 'facebook': 10, 'youtube': 11, 'towers': 12, 'media': 13, 'system': 14, 'covid19': 15, 'networks': 16, 'harrelson': 17, 'woody': 18, 'chinese': 19, 'countries': 20, 'americans': 21, 'us': 22, 'wuhan': 23, 'uk': 24, 'world': 25, 'pandemic': 26, 'someone': 27, 'covid': 28, 'sense': 29, 'africa': 30, 'government': 31, 'information': 32, 'something': 33, 'cases': 34, 'thing': 35, 'china': 36, 'robinson': 37, 'immigration': 38, 'evidence': 39, 'fact': 40, 'disease': 41, 'iran': 42, 'health': 43, 'charge': 44, 'vaccine': 45, 'american': 46, 'gates': 47, 'everyone': 48, 'doctor': 49, 'deaths': 50, 'patients': 51, 'person': 52, 'everything': 53, 'fauci': 54, 'idea': 55, 'things': 56, 'point': 57, 'numbers': 58, 'life': 59, 'trump': 60, 'doctors': 61, 'lab': 62, 'viruses': 63, 'country': 64}\n{'START': 0, 'TERMINATE': 1, 'conspiracy theory': 0, 'technology': 1, 'something': 2, 'us': 3, 'cases': 4, 'coronavirus': 5, 'thing': 6, 'towers': 7, '5g': 8, 'youtube': 9, 'spread': 10, 'time': 11, 'china': 12, 'video': 13, 'chinese': 14, 'robinson': 15, 'immigration': 16, 'questions': 17, 'masts': 18, 'covid19': 19, 'claims': 20, 'post': 21, 'times': 22, 'media': 23, 'facebook': 24, 'evidence': 25, 'system': 26, 'world': 27, 'pandemic': 28, 'countries': 29, 'uk': 30, 'icke': 31, 'vaccine': 32, 'gates': 33, 'symptoms': 34, 'fact': 35, 'information': 36, 'disease': 37, 'iran': 38, 'health': 39, 'charge': 40, 'american': 41, 'wuhan': 42, 'everyone': 43, 'doctor': 44, 'africa': 45, 'deaths': 46, 'patients': 47, 'person': 48, 'someone': 49, 'everything': 50, 'americans': 51, 'news': 52, 'fauci': 53, 'government': 54, 'things': 55, 'point': 56, 'idea': 57, 'numbers': 58, 'israel': 59, 'life': 60, 'sense': 61, 'trump': 62, 'doctors': 63, 'lab': 64, 'viruses': 65, 'country': 66}\n{'START': 0, 'TERMINATE': 1, 'conspiracy theory': 0, 'time': 1, 'pandemic': 2, 'coronavirus': 3, 'covid19': 4, '5g': 5, 'system': 6, 'health': 7, 'robinson': 8, 'immigration': 9, 'charge': 10, 'something': 11, 'us': 12, 'cases': 13, 'media': 14, 'video': 15, 'spread': 16, 'claims': 17, 'post': 18, 'times': 19, 'vaccine': 20, 'american': 21, 'gates': 22, 'facebook': 23, 'countries': 24, 'youtube': 25, 'wuhan': 26, 'technology': 27, 'everyone': 28, 'masts': 29, 'fact': 30, 'doctor': 31, 'africa': 32, 'deaths': 33, 'patients': 34, 'person': 35, 'someone': 36, 'everything': 37, 'symptoms': 38, 'icke': 39, 'americans': 40, 'news': 41, 'fauci': 42, 'government': 43, 'things': 44, 'point': 45, 'world': 46, 'information': 47, 'chinese': 48, 'idea': 49, 'numbers': 50, 'evidence': 51, 'disease': 52, 'china': 53, 'uk': 54, 'israel': 55, 'life': 56, 'sense': 57, 'trump': 58, 'doctors': 59, 'lab': 60, 'viruses': 61, 'iran': 62, 'country': 63, 'anything': 64, 'flu': 65, 'thing': 66, 'hospital': 67, 'jews': 68}\n{'START': 0, 'TERMINATE': 1, '5g': 0, 'coronavirus': 1, 'conspiracy theory': 2, 'time': 3, 'masts': 4, 'covid19': 5, 'gates': 6, 'pandemic': 7, 'fact': 8, 'doctor': 9, 'africa': 10, 'vaccine': 11, 'deaths': 12, 'patients': 13, 'something': 14, 'person': 15, 'someone': 16, 'video': 17, 'everything': 18, 'youtube': 19, 'symptoms': 20, 'claims': 21, 'technology': 22, 'icke': 23, 'times': 24, 'americans': 25, 'news': 26, 'fauci': 27, 'government': 28, 'health': 29, 'things': 30, 'point': 31, 'world': 32, 'facebook': 33, 'information': 34, 'chinese': 35, 'post': 36, 'idea': 37, 'countries': 38, 'numbers': 39, 'evidence': 40, 'media': 41, 'disease': 42, 'china': 43, 'spread': 44, 'uk': 45, 'israel': 46, 'life': 47, 'everyone': 48, 'us': 49, 'cases': 50, 'sense': 51, 'trump': 52, 'wuhan': 53, 'online': 54, 'doctors': 55, 'system': 56, 'lab': 57, 'viruses': 58, 'iran': 59, 'country': 60, 'anything': 61, 'flu': 62, 'thing': 63, 'hospital': 64, 'jews': 65, 'beer': 66, 'research': 67}\n{'START': 0, 'TERMINATE': 1, 'conspiracy theory': 0, 'media': 1, 'countries': 2, 'spread': 3, 'china': 4, 'life': 5, 'uk': 6, 'masts': 7, 'coronavirus': 8, 'everyone': 9, 'person': 10, '5g': 11, 'facebook': 12, 'someone': 13, 'us': 14, 'pandemic': 15, 'cases': 16, 'fauci': 17, 'americans': 18, 'government': 19, 'world': 20, 'sense': 21, 'deaths': 22, 'trump': 23, 'disease': 24, 'technology': 25, 'covid19': 26, 'wuhan': 27, 'video': 28, 'times': 29, 'online': 30, 'youtube': 31, 'claims': 32, 'symptoms': 33, 'post': 34, 'chinese': 35, 'idea': 36, 'doctors': 37, 'patients': 38, 'doctor': 39, 'news': 40, 'information': 41, 'comments': 42, 'system': 43, 'lab': 44, 'vaccine': 45, 'viruses': 46, 'iran': 47, 'country': 48, 'gates': 49, 'point': 50, 'state': 51, 'numbers': 52, 'evidence': 53, 'health': 54, 'anything': 55, 'flu': 56, 'fact': 57, 'time': 58, 'africa': 59, 'thing': 60, 'something': 61, 'hospital': 62, 'jews': 63, 'beer': 64, 'research': 65, 'everything': 66, 'cells': 67, 'ruth': 68}\n"
    }
   ],
   "source": [
    "date_real = to_date(date)\n",
    "date_end_real = to_date(date_end)\n",
    "\n",
    "with open(results + \"/tfidfedNER25.txt\", \"r\") as f:\n",
    "    words = f.read().splitlines()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "while date_real <= date_end_real:    \n",
    "    trajs = []\n",
    "    date_margin = create_range(date_real)\n",
    "\n",
    "    S_tfidf = create_dict(words[counter])\n",
    "    for key in S_use:\n",
    "        if key not in S_tfidf:\n",
    "            S_tfidf[key] = S_use[key]\n",
    "\n",
    "    for d in date_margin:\n",
    "        ner_file = path + from_date(d) + \"/into_relex_relations_-1.csv\"\n",
    "        trajs.extend(extract_traj(ner_file, S_tfidf))\n",
    "\n",
    "    plot_fig(trajs, from_date(date_real))\n",
    "    date_real += timedelta(days = 1)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities = \"Results0423/communities.txt\"\n",
    "with open(communities, \"r\") as f:\n",
    "    list_lines = f.readlines()\n",
    "    for l in list_lines:\n",
    "        G=nx.Graph()\n",
    "        match  = re.findall(r'{(.+?)}', l)\n",
    "        G.add_nodes_from(match, shape='ellipse')\n",
    "        A = nx.nx_agraph.to_agraph(G)\n",
    "        A.layout('circo')\n",
    "        A.draw(results + \"/Communities/step\" + str(l[0:4]) + '.png')"
   ]
  }
 ]
}